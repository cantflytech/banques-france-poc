{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed1e1584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion avec Cr√©dit Mutuel termin√©e et enregistr√©e dans : output/agences_combined_lokker_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === üìÇ Chemins des fichiers ===\n",
    "OUTPUT_COMBINED = \"output/agences_combined_lokker_ready.csv\"\n",
    "INPUT_CM = \"agences_cm_geocoded/credit_mutuel_agences_full_progress.csv\"\n",
    "\n",
    "# === üîÅ Chargement des deux datasets ===\n",
    "df_combined = pd.read_csv(OUTPUT_COMBINED)\n",
    "df_cm = pd.read_csv(INPUT_CM)\n",
    "\n",
    "# === ‚ûï Ajout de la colonne source manquante pour le Cr√©dit Mutuel ===\n",
    "df_cm['source'] = \"Cr√©dit Mutuel\"\n",
    "\n",
    "# === üßπ Harmonisation (si besoin : nettoyage d'espaces ou doublons) ===\n",
    "df_cm = df_cm[['nom', 'adresse', 'code_postal', 'latitude', 'longitude', 'region_source', 'source']]\n",
    "df_combined = df_combined[['nom', 'adresse', 'code_postal', 'latitude', 'longitude', 'region_source', 'source']]\n",
    "\n",
    "# === üîó Fusion\n",
    "df_merged = pd.concat([df_combined, df_cm], ignore_index=True)\n",
    "\n",
    "# === ‚ùå Suppression des lignes sans coordonn√©es\n",
    "df_merged = df_merged.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# === üíæ Sauvegarde\n",
    "df_merged.to_csv(OUTPUT_COMBINED, index=False)\n",
    "print(\"‚úÖ Fusion avec Cr√©dit Mutuel termin√©e et enregistr√©e dans :\", OUTPUT_COMBINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e871e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\iroum\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyproj\\crs\\crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n",
      "c:\\Users\\iroum\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyproj\\crs\\crs.py:143: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method. When making the change, be mindful of axis order changes: https://pyproj4.github.io/pyproj/stable/gotchas.html#axis-order-changes-in-proj-6\n",
      "  in_crs_string = _prepare_from_proj_string(in_crs_string)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['X_lambert_2', 'Y_lambert_2'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 22\u001b[39m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     20\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m df_ce[[\u001b[33m'\u001b[39m\u001b[33mlatitude\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mlongitude\u001b[39m\u001b[33m'\u001b[39m]] = \u001b[43mdf_ce\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX_lambert_2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mY_lambert_2\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.apply(\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mlambda\u001b[39;00m row: pd.Series(convert_lambert_to_latlon(row[\u001b[33m'\u001b[39m\u001b[33mX_lambert_2\u001b[39m\u001b[33m'\u001b[39m], row[\u001b[33m'\u001b[39m\u001b[33mY_lambert_2\u001b[39m\u001b[33m'\u001b[39m])),\n\u001b[32m     24\u001b[39m     axis=\u001b[32m1\u001b[39m\n\u001b[32m     25\u001b[39m )\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# === 3. Standardiser les colonnes pour merge ===\u001b[39;00m\n\u001b[32m     28\u001b[39m df_ce[\u001b[33m'\u001b[39m\u001b[33mnom\u001b[39m\u001b[33m'\u001b[39m] = df_ce[\u001b[33m'\u001b[39m\u001b[33mnom_agence\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iroum\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4112\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4115\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4116\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iroum\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\iroum\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index(['X_lambert_2', 'Y_lambert_2'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyproj\n",
    "\n",
    "# === üìÇ Fichiers ===\n",
    "INPUT_CE = \"agences_ce/agences-caisse-depargne0.csv\"\n",
    "OUTPUT_COMBINED = \"output/agences_combined_lokker_ready.csv\"\n",
    "\n",
    "# === 1. Charger les donn√©es Caisse d'√âpargne ===\n",
    "df_ce = pd.read_csv(INPUT_CE, sep=';', dtype=str)\n",
    "\n",
    "# === 2. Conversion Lambert II vers Latitude/Longitude ===\n",
    "proj_lambert2 = pyproj.Proj(init=\"epsg:27572\")  # Lambert II √©tendu\n",
    "proj_wgs84 = pyproj.Proj(init=\"epsg:4326\")\n",
    "\n",
    "def convert_lambert_to_latlon(x, y):\n",
    "    try:\n",
    "        lon, lat = pyproj.transform(proj_lambert2, proj_wgs84, float(x), float(y))\n",
    "        return lat, lon\n",
    "    except:\n",
    "        return None, None\n",
    "\n",
    "df_ce[['latitude', 'longitude']] = df_ce[['X_lambert_2', 'Y_lambert_2']].apply(\n",
    "    lambda row: pd.Series(convert_lambert_to_latlon(row['X_lambert_2'], row['Y_lambert_2'])),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# === 3. Standardiser les colonnes pour merge ===\n",
    "df_ce['nom'] = df_ce['nom_agence']\n",
    "df_ce['adresse'] = df_ce['adresse1'].fillna('') + ' ' + df_ce['adresse2'].fillna('')\n",
    "df_ce['code_postal'] = df_ce['code_postal']\n",
    "df_ce['region_source'] = df_ce['libelle_caisse_de_rattachement']\n",
    "df_ce['source'] = \"Caisse d'√âpargne\"\n",
    "\n",
    "# === 4. Garder uniquement les colonnes standardis√©es ===\n",
    "df_ce_clean = df_ce[['nom', 'adresse', 'code_postal', 'latitude', 'longitude', 'region_source', 'source']]\n",
    "\n",
    "# === 5. Charger le fichier existant et concat√©ner ===\n",
    "df_combined = pd.read_csv(OUTPUT_COMBINED)\n",
    "df_merged = pd.concat([df_combined, df_ce_clean], ignore_index=True)\n",
    "\n",
    "# === 6. Nettoyer les NaN si n√©cessaire ===\n",
    "df_merged = df_merged.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# === 7. Sauvegarder ===\n",
    "df_merged.to_csv(OUTPUT_COMBINED, index=False)\n",
    "print(\"‚úÖ Fusion termin√©e et enregistr√©e dans :\", OUTPUT_COMBINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c4f9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Banque Populaire ajout√©e √† : output/agences_combined_lokker_ready.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\iroum\\AppData\\Local\\Temp\\ipykernel_2476\\3928741125.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bp_clean['latitude'] = pd.to_numeric(df_bp_clean['latitude'], errors='coerce')\n",
      "C:\\Users\\iroum\\AppData\\Local\\Temp\\ipykernel_2476\\3928741125.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_bp_clean['longitude'] = pd.to_numeric(df_bp_clean['longitude'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# === üìÇ Fichiers\n",
    "INPUT_BP = \"agences_bp/agences-banque-populaire.csv\"\n",
    "OUTPUT_COMBINED = \"output/agences_combined_lokker_ready.csv\"\n",
    "\n",
    "# === üîÅ Lecture des fichiers\n",
    "df_bp = pd.read_csv(INPUT_BP, sep=';', dtype=str)\n",
    "df_combined = pd.read_csv(OUTPUT_COMBINED)\n",
    "\n",
    "# === üßº Nettoyage & transformation coordonn√©es\n",
    "# S√©parer \"lat,lon\" en deux colonnes\n",
    "df_bp[['latitude', 'longitude']] = df_bp['coordonnees_gps'].str.split(',', expand=True)\n",
    "\n",
    "# Nettoyer les champs\n",
    "df_bp['nom'] = df_bp['Nom_Guichet']\n",
    "df_bp['adresse'] = df_bp['Rue'].fillna('') + ' ' + df_bp['Complement_adresse'].fillna('') + ' ' + df_bp['Ville'].fillna('')\n",
    "df_bp['code_postal'] = df_bp['Code_Postal']\n",
    "df_bp['source'] = df_bp['Libell√©_Marque']  # ex: Banque Populaire\n",
    "df_bp['region_source'] = \"\"  # facultatif ou √† calculer si tu veux\n",
    "\n",
    "# Ne garder que les colonnes n√©cessaires\n",
    "df_bp_clean = df_bp[['nom', 'adresse', 'code_postal', 'latitude', 'longitude', 'region_source', 'source']]\n",
    "\n",
    "# Convertir les coordonn√©es en float\n",
    "df_bp_clean['latitude'] = pd.to_numeric(df_bp_clean['latitude'], errors='coerce')\n",
    "df_bp_clean['longitude'] = pd.to_numeric(df_bp_clean['longitude'], errors='coerce')\n",
    "\n",
    "# Supprimer les lignes sans coordonn√©es valides\n",
    "df_bp_clean = df_bp_clean.dropna(subset=['latitude', 'longitude'])\n",
    "\n",
    "# === üîó Fusion\n",
    "df_final = pd.concat([df_combined, df_bp_clean], ignore_index=True)\n",
    "\n",
    "# === üíæ Sauvegarde\n",
    "df_final.to_csv(OUTPUT_COMBINED, index=False)\n",
    "print(\"‚úÖ Banque Populaire ajout√©e √† :\", OUTPUT_COMBINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "013b99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#updt by the lat lon found from geocoding from the postal code\n",
    "#change region souce to \"Banque Populaire\" pour all rows\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"Final_clean/agences-ce_merged_pb.csv\")\n",
    "df['region_source'] = \"Caisse d'√âpargne\"\n",
    "df.to_csv(\"Final_clean/agences-ce_merged_pb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f757748",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[115, df.columns.get_indexer(['latitude', 'longitude'])] = [49.21667, 1.16667]\n",
    "df.iloc[333, df.columns.get_indexer(['latitude', 'longitude'])] = [45.4411934, 4.3859445]\n",
    "df.iloc[358, df.columns.get_indexer(['latitude', 'longitude'])] = [46.84314727783203, -0.4944003224372864]\n",
    "df.iloc[607, df.columns.get_indexer(['latitude', 'longitude'])] = [47.2711217, -1.623206]\n",
    "df.to_csv(\"agences-ce_merged_pb_geocoded/agences-ce_merged_pb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a195dd5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom</th>\n",
       "      <th>adresse</th>\n",
       "      <th>code_postal</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>region_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nom, adresse, code_postal, latitude, longitude, region_source]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#open agences-banque-populaire_normalized.csv and get the lat missing values from geocoding\n",
    "# --- IGNORE ---\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"agences-ce_merged_pb_geocoded/agences-ce_merged_pb.csv\")\n",
    "df[df['latitude'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1fb133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Coordonn√©es manquantes compl√©t√©es selon le code postal.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Dictionnaire code postal ‚Üí (latitude, longitude)\n",
    "cp_coords = {\n",
    "    \"69337\": (45.7597, 4.8422),\n",
    "    \"91042\": (48.6239, 2.4294),\n",
    "    \"75013\": (48.8296, 2.3570),\n",
    "    \"25051\": (47.2488, 6.0182),\n",
    "    \"34078\": (43.6111, 3.8767),\n",
    "    \"38490\": (45.5236, 5.5850),\n",
    "    \"05100\": (44.8992, 6.6427),\n",
    "    \"38217\": (45.5161, 4.8744),\n",
    "    \"69211\": (45.7600, 4.8500),\n",
    "    \"42007\": (45.4397, 4.3872),\n",
    "    \"57021\": (49.1193, 6.1757),\n",
    "    \"78183\": (48.7742, 2.0455),\n",
    "    \"63172\": (45.7708, 3.0872),\n",
    "    \"43102\": (45.2961, 3.3836),\n",
    "    \"43010\": (45.0424, 3.8829),\n",
    "    \"42161\": (45.5286, 4.2608),\n",
    "    \"75204\": (48.8566, 2.3522),\n",
    "    \"21000\": (47.3220, 5.0415),\n",
    "    \"75005\": (48.8462, 2.3526),\n",
    "    \"60600\": (49.3831, 2.4163),\n",
    "    \"15017\": (44.9260, 2.4409),\n",
    "    \"42308\": (46.0339, 4.0681),\n",
    "    \"42005\": (45.4397, 4.3872),\n",
    "}\n",
    "\n",
    "df = pd.read_csv(\"agences_banque_populaire_geocoded/agences-banque-populaire_normalized.csv\")\n",
    "\n",
    "# Remplir les lat/lon manquantes selon le code postal\n",
    "def fill_lat_lon(row):\n",
    "    if pd.isna(row['latitude']) and str(row['code_postal']) in cp_coords:\n",
    "        lat, lon = cp_coords[str(row['code_postal'])]\n",
    "        row['latitude'] = lat\n",
    "        row['longitude'] = lon\n",
    "    return row\n",
    "\n",
    "df = df.apply(fill_lat_lon, axis=1)\n",
    "\n",
    "df.to_csv(\"agences_banque_populaire_geocoded/agences-banque-populaire_normalized.csv\", index=False)\n",
    "print(\"‚úÖ Coordonn√©es manquantes compl√©t√©es selon le code postal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce657878",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change Final_clean/agences_bnp_merged_pb_fixed.csv csv to execl\n",
    "import pandas as pd\n",
    "import csv\n",
    "df = pd.read_csv(\"Final_clean/agences-ce_merged_pb.csv\",\n",
    "                 sep=\",\", engine=\"python\", encoding=\"utf-8-sig\",\n",
    "                 quotechar='\"', quoting=csv.QUOTE_MINIMAL, escapechar=\"\\\\\")\n",
    "\n",
    "df.to_excel(\"Final_clean/agences_ce_merged_pb.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
