{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03d7408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç R√©gion : bretagne\n",
      "‚ÑπÔ∏è Pas de banni√®re de cookies d√©tect√©e (ou d√©j√† accept√©e)\n",
      "üü¢ Clic 1 sur 'Voir plus'\n",
      "üü¢ Clic 2 sur 'Voir plus'\n",
      "üü¢ Clic 3 sur 'Voir plus'\n",
      "üü¢ Clic 4 sur 'Voir plus'\n",
      "üü¢ Clic 5 sur 'Voir plus'\n",
      "üü¢ Clic 6 sur 'Voir plus'\n",
      "üü¢ Clic 7 sur 'Voir plus'\n",
      "üü¢ Clic 8 sur 'Voir plus'\n",
      "üü¢ Clic 9 sur 'Voir plus'\n",
      "‚úÖ Plus de bouton 'Voir plus'\n",
      "‚úÖ 92 agences sauvegard√©es dans agences_bnp\\bretagne.csv\n",
      "\n",
      "üåç R√©gion : auvergne-rhone-alpes\n",
      "‚ÑπÔ∏è Pas de banni√®re de cookies d√©tect√©e (ou d√©j√† accept√©e)\n",
      "üü¢ Clic 1 sur 'Voir plus'\n",
      "üü¢ Clic 2 sur 'Voir plus'\n",
      "üü¢ Clic 3 sur 'Voir plus'\n",
      "üü¢ Clic 4 sur 'Voir plus'\n",
      "üü¢ Clic 5 sur 'Voir plus'\n",
      "üü¢ Clic 6 sur 'Voir plus'\n",
      "üü¢ Clic 7 sur 'Voir plus'\n",
      "üü¢ Clic 8 sur 'Voir plus'\n",
      "üü¢ Clic 9 sur 'Voir plus'\n",
      "üü¢ Clic 10 sur 'Voir plus'\n",
      "üü¢ Clic 11 sur 'Voir plus'\n",
      "üü¢ Clic 12 sur 'Voir plus'\n",
      "üü¢ Clic 13 sur 'Voir plus'\n",
      "üü¢ Clic 14 sur 'Voir plus'\n",
      "üü¢ Clic 15 sur 'Voir plus'\n",
      "üü¢ Clic 16 sur 'Voir plus'\n",
      "üü¢ Clic 17 sur 'Voir plus'\n",
      "üü¢ Clic 18 sur 'Voir plus'\n",
      "üü¢ Clic 19 sur 'Voir plus'\n",
      "üü¢ Clic 20 sur 'Voir plus'\n",
      "üü¢ Clic 21 sur 'Voir plus'\n",
      "üü¢ Clic 22 sur 'Voir plus'\n",
      "üü¢ Clic 23 sur 'Voir plus'\n",
      "üü¢ Clic 24 sur 'Voir plus'\n",
      "‚úÖ Plus de bouton 'Voir plus'\n",
      "‚úÖ 246 agences sauvegard√©es dans agences_bnp\\auvergne-rhone-alpes.csv\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "def setup_driver():\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    # Ne pas activer le mode headless pour que tout se charge correctement\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    driver.set_window_size(616, 970)  # Taille trouv√©e via ton enregistrement\n",
    "    driver.set_page_load_timeout(60)\n",
    "    return driver\n",
    "\n",
    "def click_voir_plus_until_end(driver, wait_time=2, max_clicks=100):\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    for i in range(max_clicks):\n",
    "        try:\n",
    "            btn = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[title='Voir plus']\")))\n",
    "            print(f\"üü¢ Clic {i+1} sur 'Voir plus'\")\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView(true);\", btn)\n",
    "            time.sleep(0.5)\n",
    "            btn.click()\n",
    "            time.sleep(wait_time)\n",
    "        except:\n",
    "            print(\"‚úÖ Plus de bouton 'Voir plus'\")\n",
    "            break\n",
    "\n",
    "def extract_agences_from_html(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    agences = []\n",
    "\n",
    "    for article in soup.select(\"article.b-result\"):\n",
    "        lat = article.get(\"data-lat\")\n",
    "        lng = article.get(\"data-lng\")\n",
    "        nom_tag = article.select_one(\"h2.b-result__name\")\n",
    "        adresse_tags = article.select(\"p.b-result__address\")\n",
    "\n",
    "        if nom_tag and len(adresse_tags) >= 2:\n",
    "            nom = nom_tag.text.strip()\n",
    "            adresse_ligne1 = adresse_tags[0].text.strip()\n",
    "            adresse_ligne2 = adresse_tags[1].text.strip()\n",
    "            adresse = f\"{adresse_ligne1}, {adresse_ligne2}\"\n",
    "            code_postal = adresse_ligne2.split()[0]\n",
    "\n",
    "            agences.append({\n",
    "                \"nom\": nom,\n",
    "                \"adresse\": adresse,\n",
    "                \"code_postal\": code_postal,\n",
    "                \"latitude\": lat,\n",
    "                \"longitude\": lng\n",
    "            })\n",
    "\n",
    "    return agences\n",
    "\n",
    "def scrape_region(region_slug, output_dir=\"agences_bnp\"):\n",
    "    url = f\"https://nos-agences.mabanque.bnpparibas/{region_slug}\"\n",
    "    driver = setup_driver()\n",
    "\n",
    "    print(f\"\\nüåç R√©gion : {region_slug}\")\n",
    "    driver.get(url)\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 5)\n",
    "        accept_btn = wait.until(EC.element_to_be_clickable((By.ID, \"didomi-notice-agree-button\")))\n",
    "        accept_btn.click()\n",
    "        print(\"üç™ Cookies accept√©s\")\n",
    "        time.sleep(1)\n",
    "    except:\n",
    "        print(\"‚ÑπÔ∏è Pas de banni√®re de cookies d√©tect√©e (ou d√©j√† accept√©e)\")\n",
    "\n",
    "\n",
    "    click_voir_plus_until_end(driver)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    agences = extract_agences_from_html(html)\n",
    "    df = pd.DataFrame(agences)\n",
    "    df.drop_duplicates(subset=[\"nom\", \"adresse\"], inplace=True)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    path = os.path.join(output_dir, f\"{region_slug}.csv\")\n",
    "    df.to_csv(path, index=False)\n",
    "    print(f\"‚úÖ {len(df)} agences sauvegard√©es dans {path}\")\n",
    "\n",
    "def scrape_all_regions():\n",
    "    regions = [\n",
    "        \"bourgogne-franche-comte\",\n",
    "        \"ile-de-france\",\n",
    "        \"hauts-de-france\",\n",
    "        \"occitanie\",\n",
    "        \"bretagne\",\n",
    "        \"auvergne-rhone-alpes\",\n",
    "        \"nouvelle-aquitaine\",\n",
    "        \"pays-de-la-loire\",\n",
    "        \"provence-alpes-cote-d-azur\",\n",
    "        \"grand-est\",\n",
    "        \"normandie\",\n",
    "        \"centre-val-de-loire\"\n",
    "    ]\n",
    "    for region in regions:\n",
    "        scrape_region(region)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scrape_all_regions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf0d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fusion termin√©e : output/agences_bnp_merged.csv\n"
     ]
    }
   ],
   "source": [
    "#fusionner tout les csv de agences_bnp dans un seul fichier \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Chemin du dossier contenant les CSV\n",
    "folder_path = \"agences_bnp\"\n",
    "\n",
    "# Liste pour stocker les DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Parcours de tous les fichiers dans le dossier\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['region_source'] = filename.replace('.csv', '')  # Ajoute une colonne pour identifier la r√©gion\n",
    "        df_list.append(df)\n",
    "\n",
    "# Fusionner tous les DataFrames\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "# Sauvegarde dans un nouveau fichier\n",
    "output_path = \"output/agences_bnp_merged.csv\"\n",
    "merged_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"‚úÖ Fusion termin√©e : {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1eac9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fichier pr√™t pour Lokker Studio : output/agences_bnp_lokker_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement du CSV existant\n",
    "df = pd.read_csv(\"output/agences_bnp_merged.csv\")\n",
    "\n",
    "# Cr√©ation de la colonne \"coordonnees\" sous forme de texte \"lat,lon\"\n",
    "df[\"coordonnees\"] = df[\"latitude\"].astype(str) + \",\" + df[\"longitude\"].astype(str)\n",
    "\n",
    "# Optionnel : r√©organiser les colonnes\n",
    "colonnes_finales = [\"nom\", \"adresse\", \"code_postal\", \"coordonnees\", \"region_source\"]\n",
    "df = df[colonnes_finales]\n",
    "\n",
    "# Sauvegarde du fichier pr√™t pour Lokker Studio\n",
    "df.to_csv(\"output/agences_bnp_lokker_ready.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "print(\"‚úÖ Fichier pr√™t pour Lokker Studio : output/agences_bnp_lokker_ready.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
